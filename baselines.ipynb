{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "import math\n",
    "from surprise import SVD, SVDpp\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise import accuracy\n",
    "from collections import defaultdict\n",
    "from surprise import  NMF, BaselineOnly, KNNBasic\n",
    "from lightfm import LightFM\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from lightfm.data import Dataset as LFMDataset\n",
    "from lightfm.evaluation import precision_at_k, recall_at_k\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "ratings_data = pd.read_csv('mooc_data/Data/mooc.train.rating', sep='\\t', names=['user', 'item', 'rating'])\n",
    "test = pd.read_csv('mooc_data/Data/mooc.test.rating', sep='\\t', names=['user', 'item', 'rating'])\n",
    "\n",
    "reader = Reader(rating_scale=(0, 1))\n",
    "train_data = Dataset.load_from_df(ratings_data[['user', 'item', 'rating']], reader)\n",
    "trainset = train_data.build_full_trainset()\n",
    "test_data = Dataset.load_from_df(test[['user', 'item', 'rating']], reader)\n",
    "testset = test_data.build_full_trainset().build_testset()\n",
    "\n",
    "\n",
    "all_users = set(ratings_data['user']).union(set(test['user']))\n",
    "all_items = set(ratings_data['item']).union(set(test['item']))\n",
    "\n",
    "\n",
    "def hit_and_ndcg_per_user(predicted_items, actual_items):\n",
    "    hits = 0\n",
    "    ndcg = 0.0\n",
    "    for rank, item in enumerate(predicted_items):\n",
    "        if item in actual_items:\n",
    "            hits += 1  \n",
    "            ndcg += 1 / np.log2(rank + 2) \n",
    "    return hits, ndcg\n",
    "\n",
    "\n",
    "def evaluate_user(recommended_items, actual_items):\n",
    "    hr = False\n",
    "    hr_count = 0\n",
    "    dcg = 0.0\n",
    "    idcg = 0.0\n",
    "    precision = 0.0\n",
    "    recall = 0.0\n",
    "    ndcg = 0.0\n",
    "    \n",
    "    if (len(actual_items) == 0):\n",
    "        return {\"Precision\": precision, \"Recall\": recall, \"HR\": hr_count, \"NDCG\": ndcg}\n",
    "    \n",
    "\n",
    "    for rank, item in enumerate(recommended_items, start=1):\n",
    "        if item in actual_items:\n",
    "            hr = True\n",
    "            precision += 1 / len(recommended_items)\n",
    "            recall += 1 / len(actual_items)\n",
    "            dcg += 1 / np.log2(rank + 2)  # rank+2 because log2(1) is 0 and ranks start at 0\n",
    "\n",
    "        # Calculate IDCG part\n",
    "        if rank <= len(actual_items):\n",
    "            idcg += 1 / np.log2(rank + 2)  # Same as DCG for the 'ideal' case\n",
    "    if hr == True:\n",
    "        hr_count += 1\n",
    "    \n",
    "    # Calculate nDCG for the user\n",
    "    ndcg = dcg / idcg if idcg > 0 else 0\n",
    "\n",
    "    return {\"Precision\": precision, \"Recall\": recall, \"HR\": hr_count, \"NDCG\": ndcg}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random\n",
    "\n",
    "# Number of recommendations\n",
    "N = 5\n",
    "\n",
    "# Generate random recommendations for each user\n",
    "recommendations = {user: random.sample(all_items, N) for user in all_users}\n",
    "\n",
    "# Initialize evaluation metrics\n",
    "recall, hr_count, ndcg_score, precision = 0, 0, 0, 0\n",
    "\n",
    "# Evaluate recommendations\n",
    "for user in all_users:\n",
    "    actual_items = test[test['user'] == user]['item'].tolist()\n",
    "    predicted_items = recommendations.get(user, [])\n",
    "    metrics = evaluate_user(predicted_items, actual_items)\n",
    "    hr_count += metrics['HR'] > 0\n",
    "    ndcg_score += metrics['NDCG']\n",
    "    recall += metrics['Recall']\n",
    "    precision += metrics['Precision']\n",
    "\n",
    "# Compute average metrics\n",
    "num_users = len(all_users)\n",
    "hr = hr_count / num_users\n",
    "ndcg = ndcg_score / num_users\n",
    "recall = recall / num_users\n",
    "precision = precision / num_users\n",
    "\n",
    "# Output results\n",
    "print(f\"HR@{N}: {hr}\")\n",
    "print(f\"nDCG@{N}: {ndcg}\")\n",
    "print(f\"Recall@{N}: {recall}\")\n",
    "print(f\"Precision@{N}: {precision}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Popular\n",
    "\n",
    "# 计算物品流行度\n",
    "item_popularity = ratings_data['item'].value_counts()\n",
    "\n",
    "# Top N\n",
    "N = 5\n",
    "top_items = item_popularity.head(N).index.tolist()\n",
    "\n",
    "# 为每个用户生成相同的推荐列表\n",
    "recommendations = {user: top_items for user in test_data['user'].unique()}\n",
    "\n",
    "# 应用评估函数\n",
    "recall, hr_count, ndcg_score, precision = 0, 0, 0, 0\n",
    "for user in test_data['user'].unique():\n",
    "    actual_items = test_data[test_data['user'] == user]['item'].tolist()\n",
    "    predicted_items = recommendations.get(user, [])\n",
    "    metrics = evaluate_user(predicted_items, actual_items)\n",
    "    hr_count += metrics['HR'] > 0\n",
    "    ndcg_score += metrics['NDCG']\n",
    "    recall += metrics['Recall']\n",
    "    precision += metrics['Precision']\n",
    "\n",
    "# 计算平均指标\n",
    "num_users = len(test_data['user'].unique())\n",
    "hr = hr_count / num_users\n",
    "ndcg = ndcg_score / num_users\n",
    "recall = recall / num_users\n",
    "precision = precision / num_users\n",
    "\n",
    "print(num_users)\n",
    "\n",
    "# 输出结果\n",
    "print(f\"HR@10: {hr}\")\n",
    "print(f\"nDCG@10: {ndcg}\")\n",
    "print(f\"Recall@10: {recall}\")\n",
    "print(f\"Precision@10: {precision}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NMF\n",
    "\n",
    "# 定义要调优的参数\n",
    "param_grid = {'n_factors': [15, 20, 25],\n",
    "              'n_epochs': [50, 100, 30]}  # PMF实现，即SVD无偏置项\n",
    "\n",
    "# 使用网格搜索进行交叉验证\n",
    "gs = GridSearchCV(NMF, param_grid, measures=['rmse'], cv=3)\n",
    "\n",
    "# 在数据集上找到最佳参数\n",
    "gs.fit(train_data)\n",
    "\n",
    "# 最佳RMSE得分\n",
    "print(gs.best_score['rmse'])\n",
    "\n",
    "# 最佳参数\n",
    "print(gs.best_params['rmse'])\n",
    "\n",
    "# 使用最佳参数训练NMF模型\n",
    "trainset = train_data.build_full_trainset()\n",
    "nmf = NMF(n_factors=gs.best_params['rmse']['n_factors'],\n",
    "           n_epochs=gs.best_params['rmse']['n_epochs'])\n",
    "# # 初始化NMF模型\n",
    "# nmf = NMF()\n",
    "# 训练模型\n",
    "nmf.fit(trainset)\n",
    "# 进行预测\n",
    "predictions = nmf.test(testset)\n",
    "\n",
    "\n",
    "# 生成推荐列表\n",
    "recommendations = defaultdict(list)\n",
    "for user in all_users:\n",
    "    for item in all_items:\n",
    "        est = nmf.predict(user, item).est\n",
    "        recommendations[user].append((item, est))\n",
    "    recommendations[user] = sorted(recommendations[user], key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "recall = 0\n",
    "hr_count = 0\n",
    "ndcg_score = 0\n",
    "for user in all_users:\n",
    "    actual_items = test[test['user'] == user]['item'].tolist()\n",
    "    predicted_items = [x[0] for x in recommendations[user]]\n",
    "    metrics = evaluate_user(predicted_items, actual_items)\n",
    "    hr_count += metrics['HR'] > 0\n",
    "    ndcg_score += metrics['NDCG']\n",
    "    recall += metrics['Recall']\n",
    "    precision += metrics['Precision']\n",
    "\n",
    "hr = hr_count / len(test['user'].unique())\n",
    "ndcg = ndcg_score / len(test['user'].unique())\n",
    "recall = recall/ len(test['user'].unique())\n",
    "\n",
    "precision = precision/ len(test['user'].unique())\n",
    "\n",
    "print(f\"Precision@10: {precision}\")\n",
    "print(f\"HR@5: {hr}\")\n",
    "print(f\"nDCG@5: {ndcg}\")\n",
    "print(f\"recall@5: {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PMF\n",
    "\n",
    "# 定义要调优的参数\n",
    "param_grid = {'n_factors': [50, 100, 150],\n",
    "              'n_epochs': [20,30,50],\n",
    "              'lr_all': [0.002],\n",
    "              'reg_all': [0.02],\n",
    "              'biased': [False]}  # PMF实现，即SVD无偏置项\n",
    "\n",
    "# 使用网格搜索进行交叉验证\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=3)\n",
    "\n",
    "# 在数据集上找到最佳参数\n",
    "gs.fit(train_data)\n",
    "\n",
    "# 最佳RMSE得分\n",
    "print(gs.best_score['rmse'])\n",
    "\n",
    "# 最佳参数\n",
    "print(gs.best_params['rmse'])\n",
    "\n",
    "# 使用最佳参数训练PMF模型\n",
    "trainset = train_data.build_full_trainset()\n",
    "pmf = SVD(n_factors=gs.best_params['rmse']['n_factors'],\n",
    "           n_epochs=gs.best_params['rmse']['n_epochs'],\n",
    "           lr_all=gs.best_params['rmse']['lr_all'],\n",
    "           reg_all=gs.best_params['rmse']['reg_all'],\n",
    "           biased=False)\n",
    "pmf.fit(trainset)\n",
    "\n",
    "# 进行预测\n",
    "predictions = pmf.test(testset)\n",
    "# 生成推荐列表\n",
    "recommendations = defaultdict(list)\n",
    "for user in all_users:\n",
    "    for item in all_items:\n",
    "        est = pmf.predict(user, item).est\n",
    "        recommendations[user].append((item, est))\n",
    "    recommendations[user] = sorted(recommendations[user], key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "recall = 0\n",
    "hr_count = 0\n",
    "ndcg_score = 0\n",
    "for user in all_users:\n",
    "    actual_items = test[test['user'] == user]['item'].tolist()\n",
    "    predicted_items = [x[0] for x in recommendations[user]]\n",
    "    metrics = evaluate_user(predicted_items, actual_items)\n",
    "    hr_count += metrics['HR'] > 0\n",
    "    ndcg_score += metrics['NDCG']\n",
    "    recall += metrics['Recall']\n",
    "\n",
    "hr = hr_count / len(test['user'].unique())\n",
    "ndcg = ndcg_score / len(test['user'].unique())\n",
    "recall = recall/ len(test['user'].unique())\n",
    "\n",
    "\n",
    "print(f\"HR@10: {hr}\")\n",
    "print(f\"nDCG@10: {ndcg}\")\n",
    "print(f\"recall@10: {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN (User + Item)\n",
    "\n",
    "# 初始化KNNBasic模型\n",
    "# 可以选择不同的相似度度量方法和配置\n",
    "sim_options = {  # 可以选择 'cosine', 'msd', 'pearson', 'pearson_baseline'\n",
    "    'user_based': False  # False 表示itemKNN，True 表示userKNN\n",
    "}\n",
    "knn = KNNBasic(sim_options=sim_options)\n",
    "\n",
    "# 训练模型\n",
    "knn.fit(trainset)\n",
    "\n",
    "# 进行预测\n",
    "predictions = knn.test(testset)\n",
    "\n",
    "# 生成推荐列表\n",
    "recommendations = defaultdict(list)\n",
    "for user in all_users:\n",
    "    for item in all_items:\n",
    "        est = knn.predict(user, item).est\n",
    "        recommendations[user].append((item, est))\n",
    "    recommendations[user] = sorted(recommendations[user], key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "recall = 0\n",
    "hr_count = 0\n",
    "ndcg_score = 0\n",
    "for user in all_users:\n",
    "    actual_items = test[test['user'] == user]['item'].tolist()\n",
    "    predicted_items = [x[0] for x in recommendations[user]]\n",
    "    metrics = evaluate_user(predicted_items, actual_items)\n",
    "    hr_count += metrics['HR'] > 0\n",
    "    ndcg_score += metrics['NDCG']\n",
    "    recall += metrics['Recall']\n",
    "    precision += metrics['Precision']\n",
    "\n",
    "hr = hr_count / len(test['user'].unique())\n",
    "ndcg = ndcg_score / len(test['user'].unique())\n",
    "recall = recall/ len(test['user'].unique())\n",
    "precision = precision/ len(test['user'].unique())\n",
    "\n",
    "print(f\"Precision@10: {precision}\")\n",
    "print(f\"HR@5: {hr}\")\n",
    "print(f\"nDCG@5: {ndcg}\")\n",
    "print(f\"recall@5: {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightFM + BPR/WARP\n",
    "\n",
    "# 准备数据集\n",
    "lfm_dataset = LFMDataset()\n",
    "# 同时传入训练集和测试集中的所有用户和物品\n",
    "all_users = set(ratings_data['user']).union(set(test['user']))\n",
    "all_items = set(ratings_data['item']).union(set(test['item']))\n",
    "lfm_dataset.fit(users=(x for x in all_users),\n",
    "                items=(x for x in all_items))\n",
    "\n",
    "# print(lfm_dataset)\n",
    "\n",
    "# 构建交互矩阵\n",
    "(interactions, _) = lfm_dataset.build_interactions(((row['user'], row['item']) for index, row in ratings_data.iterrows()))\n",
    "\n",
    "# print(interactions)\n",
    "\n",
    "# 训练BPR模型\n",
    "# loss = 'warp'\n",
    "model = LightFM(loss='bpr')\n",
    "\n",
    "\n",
    "\n",
    "model.fit(interactions, epochs=10)\n",
    "\n",
    "\n",
    "\n",
    "# 构建测试集\n",
    "(test_interactions, _) = lfm_dataset.build_interactions(((row['user'], row['item']) for index, row in test.iterrows()))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 生成推荐列表\n",
    "num_users, num_items = lfm_dataset.interactions_shape()\n",
    "recommendations = defaultdict(list)\n",
    "for user_id in range(num_users):\n",
    "    scores = model.predict(user_id, np.arange(num_items))\n",
    "    top_items = np.argsort(-scores)[:5]\n",
    "    recommendations[user_id] = top_items\n",
    "\n",
    "# 计算评价指标\n",
    "recall = 0\n",
    "hr_count = 0\n",
    "ndcg_score = 0\n",
    "precision = 0\n",
    "for user_id in range(num_users):\n",
    "    actual_items = test[test['user'] == user_id]['item'].tolist()\n",
    "    predicted_items = recommendations[user_id]\n",
    "    metrics = evaluate_user(predicted_items, actual_items)\n",
    "    hr_count += metrics['HR'] > 0\n",
    "    ndcg_score += metrics['NDCG']\n",
    "    recall += metrics['Recall']\n",
    "    precision += metrics['Precision']\n",
    "\n",
    "hr = hr_count / len(test['user'].unique())\n",
    "ndcg = ndcg_score / len(test['user'].unique())\n",
    "recall = recall / len(test['user'].unique())\n",
    "precision = precision / len(test['user'].unique())\n",
    "\n",
    "# 输出结果\n",
    "print(f\"Recall@5: {recall}\")\n",
    "print(f\"Precision@5: {precision}\")\n",
    "print(f\"HR@5: {hr}\")\n",
    "print(f\"nDCG@5: {ndcg}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
